{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Ñomet_segmentation_aug.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7DmSr0Cb0KXV",
        "I7XGAb4Y0ZZ4",
        "iCD6PvALlCBj",
        "Wn9sgxNPA9-y",
        "GihqLdyTIVp5",
        "5y_hcUQx899y"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68W2ccO49jn9",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEFBEDIB9muR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pretrainedmodels\n",
        "!pip install albumentations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNiM2EiJiYrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip alldata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktlfdeFKcvl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from PIL import Image\n",
        "import scipy.misc\n",
        "import os\n",
        "# import utils\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJrpnNpN9tbv",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQk1SX8v1nfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "\n",
        "def dice_loss(preds, trues, weight=None, is_average=True, eps=1):\n",
        "    num = preds.size(0)\n",
        "    preds = preds.view(num, -1)\n",
        "    trues = trues.view(num, -1)\n",
        "    if weight is not None:\n",
        "        w = torch.autograd.Variable(weight).view(num, -1)\n",
        "        preds = preds * w\n",
        "        trues = trues * w\n",
        "    intersection = (preds * trues).sum(1)\n",
        "    scores = 2. * (intersection + eps) / (preds.sum(1) + trues.sum(1) + eps)\n",
        "\n",
        "    if is_average:\n",
        "        score = scores.sum() / num\n",
        "        return torch.clamp(score, 0., 1.)\n",
        "    else:\n",
        "        return scores\n",
        "\n",
        "    \n",
        "def jaccard_loss(preds, trues, weight=None, is_average=True, eps=1e-3):\n",
        "    num = preds.size(0)\n",
        "    preds = preds.view(num, -1)\n",
        "    trues = trues.view(num, -1)\n",
        "    if weight is not None:\n",
        "        w = torch.autograd.Variable(weight).view(num, -1)\n",
        "        preds = preds * w\n",
        "        trues = trues * w\n",
        "    intersection = (preds * trues).sum(1)\n",
        "    scores = (intersection + eps) / ((preds + trues).sum(1) - intersection + eps)\n",
        "\n",
        "    if is_average:\n",
        "        score = scores.sum()/num\n",
        "        return torch.clamp(score, 0., 1.)\n",
        "    else:\n",
        "        return scores\n",
        "\n",
        "\n",
        "def dice_clamp(preds, trues, is_average=True):\n",
        "    preds = torch.round(preds)\n",
        "    return dice_loss(preds, trues, is_average=is_average)\n",
        "\n",
        "\n",
        "def jaccard_clamp(preds, trues, is_average=True):\n",
        "    preds = torch.round(preds)\n",
        "    return jaccard_loss(preds, trues, is_average=is_average)    \n",
        "\n",
        "\n",
        "class FocalLossBinary(nn.Module):\n",
        "    \"\"\"Focal loss puts more weight on more complicated examples.\n",
        "    https://github.com/warmspringwinds/pytorch-segmentation-detection/blob/master/pytorch_segmentation_detection/losses.py\n",
        "    output is log_softmax\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, gamma=2, size_average=True, reduce=True):\n",
        "        super(FocalLossBinary, self).__init__(size_average=size_average, reduce=reduce)\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "\n",
        "        outputs = F.logsigmoid(outputs)\n",
        "        logpt = -F.binary_cross_entropy_with_logits(outputs, targets.float(), reduce=False)\n",
        "        pt = torch.exp(logpt)\n",
        "\n",
        "        # compute the loss\n",
        "        loss = -((1 - pt).pow(self.gamma)) * logpt\n",
        "\n",
        "        # averaging (or not) loss\n",
        "        if self.size_average:\n",
        "            return loss.mean()\n",
        "        else:\n",
        "            return loss.sum()\n",
        "\n",
        "        \n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, size_average=True, eps=1):\n",
        "        super().__init__()\n",
        "        self.size_average = size_average\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, input, target, weight=None):\n",
        "        return 1-dice_loss(torch.sigmoid(input), target, \n",
        "                           weight=weight, is_average=self.size_average, eps=self.eps)\n",
        "\n",
        "\n",
        "class BCEDiceLoss(nn.Module):\n",
        "    def __init__(self, size_average=True):\n",
        "        super().__init__()\n",
        "        self.size_average = size_average\n",
        "        self.dice = DiceLoss(size_average=size_average)\n",
        "\n",
        "    def forward(self, input, target, weight=None):\n",
        "        return nn.modules.loss.BCEWithLogitsLoss(size_average=self.size_average, \n",
        "                                                 weight=weight)(input, target) + self.dice(input, target, weight=weight)\n",
        "    \n",
        "class JaccardLoss(nn.Module):\n",
        "    def __init__(self, size_average=True, eps=100):\n",
        "        super().__init__()\n",
        "        self.size_average = size_average\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, input, target, weight=None):\n",
        "        return 1-jaccard_loss(torch.sigmoid(input), target, \n",
        "                              weight=weight, is_average=self.size_average, eps=self.eps)\n",
        "\n",
        "\n",
        "class BCEJaccardLoss(nn.Module):\n",
        "    def __init__(self, size_average=True):\n",
        "        super().__init__()\n",
        "        self.size_average = size_average\n",
        "        self.eps = 100\n",
        "        self.jaccard = JaccardLoss(size_average=size_average, eps=self.eps)\n",
        "\n",
        "    def forward(self, input, target, weight=None):\n",
        "        return nn.modules.loss.BCEWithLogitsLoss(size_average=self.size_average, \n",
        "                                                 weight=weight)(input, target) + self.jaccard(input, target, weight=weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2CaKQOW1p-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def save_checkpoint(checkpoint_path, model, optimizer):\n",
        "    state = {'state_dict': model.state_dict(),\n",
        "             'optimizer' : optimizer.state_dict()}\n",
        "    torch.save(state, checkpoint_path)\n",
        "    print('model saved to %s' % checkpoint_path)\n",
        "    \n",
        "def load_checkpoint(checkpoint_path, model, optimizer):\n",
        "    state = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(state['state_dict'])\n",
        "    optimizer.load_state_dict(state['optimizer'])\n",
        "    print('model loaded from %s' % checkpoint_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AismkDo1Q-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch\n",
        "from torchvision import models\n",
        "import torchvision\n",
        "from pretrainedmodels import models as pmodels\n",
        "\n",
        "def conv3x3(in_, out):\n",
        "    return nn.Conv2d(in_, out, 3, padding=1)\n",
        "\n",
        "\n",
        "class ConvRelu(nn.Module):\n",
        "    def __init__(self, in_, out):\n",
        "        super().__init__()\n",
        "        self.conv = conv3x3(in_, out)\n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, middle_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            ConvRelu(in_channels, middle_channels),\n",
        "            nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "\n",
        "class UNet11(nn.Module):\n",
        "    def __init__(self, num_filters=32, pretrained=False):\n",
        "        \"\"\"\n",
        "        :param num_classes:\n",
        "        :param num_filters:\n",
        "        :param pretrained:\n",
        "            False - no pre-trained network is used\n",
        "            True  - encoder is pre-trained with VGG11\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.encoder = models.vgg11(pretrained=pretrained).features\n",
        "\n",
        "        self.relu = self.encoder[1]\n",
        "        self.conv1 = self.encoder[0]\n",
        "        self.conv2 = self.encoder[3]\n",
        "        self.conv3s = self.encoder[6]\n",
        "        self.conv3 = self.encoder[8]\n",
        "        self.conv4s = self.encoder[11]\n",
        "        self.conv4 = self.encoder[13]\n",
        "        self.conv5s = self.encoder[16]\n",
        "        self.conv5 = self.encoder[18]\n",
        "\n",
        "        self.center = DecoderBlock(num_filters * 8 * 2, num_filters * 8 * 2, num_filters * 8)\n",
        "        self.dec5 = DecoderBlock(num_filters * (16 + 8), num_filters * 8 * 2, num_filters * 8)\n",
        "        self.dec4 = DecoderBlock(num_filters * (16 + 8), num_filters * 8 * 2, num_filters * 4)\n",
        "        self.dec3 = DecoderBlock(num_filters * (8 + 4), num_filters * 4 * 2, num_filters * 2)\n",
        "        self.dec2 = DecoderBlock(num_filters * (4 + 2), num_filters * 2 * 2, num_filters)\n",
        "        self.dec1 = ConvRelu(num_filters * (2 + 1), num_filters)\n",
        "\n",
        "        self.final = nn.Conv2d(num_filters, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.relu(self.conv1(x))\n",
        "        conv2 = self.relu(self.conv2(self.pool(conv1)))\n",
        "        conv3s = self.relu(self.conv3s(self.pool(conv2)))\n",
        "        conv3 = self.relu(self.conv3(conv3s))\n",
        "        conv4s = self.relu(self.conv4s(self.pool(conv3)))\n",
        "        conv4 = self.relu(self.conv4(conv4s))\n",
        "        conv5s = self.relu(self.conv5s(self.pool(conv4)))\n",
        "        conv5 = self.relu(self.conv5(conv5s))\n",
        "\n",
        "        center = self.center(self.pool(conv5))\n",
        "\n",
        "        dec5 = self.dec5(torch.cat([center, conv5], 1))\n",
        "        dec4 = self.dec4(torch.cat([dec5, conv4], 1))\n",
        "        dec3 = self.dec3(torch.cat([dec4, conv3], 1))\n",
        "        dec2 = self.dec2(torch.cat([dec3, conv2], 1))\n",
        "        dec1 = self.dec1(torch.cat([dec2, conv1], 1))\n",
        "        return self.final(dec1)\n",
        "\n",
        "\n",
        "def unet11(pretrained=False, **kwargs):\n",
        "    \"\"\"\n",
        "    pretrained:\n",
        "            False - no pre-trained network is used\n",
        "            True  - encoder is pre-trained with VGG11\n",
        "            carvana - all weights are pre-trained on\n",
        "                Kaggle: Carvana dataset https://www.kaggle.com/c/carvana-image-masking-challenge\n",
        "    \"\"\"\n",
        "    model = UNet11(pretrained=pretrained, **kwargs)\n",
        "\n",
        "    if pretrained == 'carvana':\n",
        "        state = torch.load('TernausNet.pt')\n",
        "        model.load_state_dict(state['model'])\n",
        "    return model\n",
        "\n",
        "\n",
        "class Interpolate(nn.Module):\n",
        "    def __init__(self, size=None, scale_factor=None, mode='nearest', align_corners=False):\n",
        "        super(Interpolate, self).__init__()\n",
        "        self.interp = nn.functional.interpolate\n",
        "        self.size = size\n",
        "        self.mode = mode\n",
        "        self.scale_factor = scale_factor\n",
        "        self.align_corners = align_corners\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.interp(x, size=self.size, scale_factor=self.scale_factor, \n",
        "                        mode=self.mode, align_corners=self.align_corners)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DecoderBlockV2(nn.Module):\n",
        "    def __init__(self, in_channels, middle_channels, out_channels, is_deconv=True):\n",
        "        super(DecoderBlockV2, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        if is_deconv:\n",
        "            \"\"\"\n",
        "                Paramaters for Deconvolution were chosen to avoid artifacts, following\n",
        "                link https://distill.pub/2016/deconv-checkerboard/\n",
        "            \"\"\"\n",
        "\n",
        "            self.block = nn.Sequential(\n",
        "                ConvRelu(in_channels, middle_channels),\n",
        "                nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=4, stride=2,\n",
        "                                   padding=1),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "        else:\n",
        "            self.block = nn.Sequential(\n",
        "                Interpolate(scale_factor=2, mode='bilinear'),\n",
        "                ConvRelu(in_channels, middle_channels),\n",
        "                ConvRelu(middle_channels, out_channels),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "\n",
        "class ResNet43Unet(nn.Module):\n",
        "    \"\"\"\n",
        "        UNet (https://arxiv.org/abs/1505.04597) with Resnet34(https://arxiv.org/abs/1512.03385) encoder\n",
        "        Proposed by Alexander Buslaev: https://www.linkedin.com/in/al-buslaev/\n",
        "        \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=1, num_filters=32, pretrained=False, is_deconv=False):\n",
        "        \"\"\"\n",
        "        :param num_classes:\n",
        "        :param num_filters:\n",
        "        :param pretrained:\n",
        "            False - no pre-trained network is used\n",
        "            True  - encoder is pre-trained with resnet34\n",
        "        :is_deconv:\n",
        "            False: bilinear interpolation is used in decoder\n",
        "            True: deconvolution is used in decoder\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.encoder = torchvision.models.resnet34(pretrained=pretrained)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv1 = nn.Sequential(self.encoder.conv1,\n",
        "                                   self.encoder.bn1,\n",
        "                                   self.encoder.relu,\n",
        "                                   self.pool)\n",
        "\n",
        "        self.conv2 = self.encoder.layer1\n",
        "\n",
        "        self.conv3 = self.encoder.layer2\n",
        "\n",
        "        self.conv4 = self.encoder.layer3\n",
        "\n",
        "        self.conv5 = self.encoder.layer4\n",
        "\n",
        "        self.center = DecoderBlockV2(512, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
        "\n",
        "        self.dec5 = DecoderBlockV2(512 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
        "        self.dec4 = DecoderBlockV2(256 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
        "        self.dec3 = DecoderBlockV2(128 + num_filters * 8, num_filters * 4 * 2, num_filters * 2, is_deconv)\n",
        "        self.dec2 = DecoderBlockV2(64 + num_filters * 2, num_filters * 2 * 2, num_filters * 2 * 2, is_deconv)\n",
        "        self.dec1 = DecoderBlockV2(num_filters * 2 * 2, num_filters * 2 * 2, num_filters, is_deconv)\n",
        "        self.dec0 = ConvRelu(num_filters, num_filters)\n",
        "        self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.conv1(x)\n",
        "        conv2 = self.conv2(conv1)\n",
        "        conv3 = self.conv3(conv2)\n",
        "        conv4 = self.conv4(conv3)\n",
        "        conv5 = self.conv5(conv4)\n",
        "\n",
        "        center = self.center(self.pool(conv5))\n",
        "\n",
        "        dec5 = self.dec5(torch.cat([center, conv5], 1))\n",
        "\n",
        "        dec4 = self.dec4(torch.cat([dec5, conv4], 1))\n",
        "        dec3 = self.dec3(torch.cat([dec4, conv3], 1))\n",
        "        dec2 = self.dec2(torch.cat([dec3, conv2], 1))\n",
        "        dec1 = self.dec1(dec2)\n",
        "        dec0 = self.dec0(dec1)\n",
        "\n",
        "        if self.num_classes > 1:\n",
        "            x_out = F.log_softmax(self.final(dec0), dim=1)\n",
        "        else:\n",
        "            x_out = self.final(dec0)\n",
        "\n",
        "        return x_out\n",
        "\n",
        "\n",
        "class UNet16(nn.Module):\n",
        "    def __init__(self, num_classes=1, num_filters=32, pretrained=False, is_deconv=False):\n",
        "        \"\"\"\n",
        "        :param num_classes:\n",
        "        :param num_filters:\n",
        "        :param pretrained:\n",
        "            False - no pre-trained network used\n",
        "            True - encoder pre-trained with VGG16\n",
        "        :is_deconv:\n",
        "            False: bilinear interpolation is used in decoder\n",
        "            True: deconvolution is used in decoder\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.encoder = torchvision.models.vgg16(pretrained=pretrained).features\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv1 = nn.Sequential(self.encoder[0],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[2],\n",
        "                                   self.relu)\n",
        "\n",
        "        self.conv2 = nn.Sequential(self.encoder[5],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[7],\n",
        "                                   self.relu)\n",
        "\n",
        "        self.conv3 = nn.Sequential(self.encoder[10],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[12],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[14],\n",
        "                                   self.relu)\n",
        "\n",
        "        self.conv4 = nn.Sequential(self.encoder[17],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[19],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[21],\n",
        "                                   self.relu)\n",
        "\n",
        "        self.conv5 = nn.Sequential(self.encoder[24],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[26],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[28],\n",
        "                                   self.relu)\n",
        "\n",
        "        self.center = DecoderBlockV2(512, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
        "\n",
        "        self.dec5 = DecoderBlockV2(512 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
        "        self.dec4 = DecoderBlockV2(512 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
        "        self.dec3 = DecoderBlockV2(256 + num_filters * 8, num_filters * 4 * 2, num_filters * 2, is_deconv)\n",
        "        self.dec2 = DecoderBlockV2(128 + num_filters * 2, num_filters * 2 * 2, num_filters, is_deconv)\n",
        "        self.dec1 = ConvRelu(64 + num_filters, num_filters)\n",
        "        self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.conv1(x)\n",
        "        conv2 = self.conv2(self.pool(conv1))\n",
        "        conv3 = self.conv3(self.pool(conv2))\n",
        "        conv4 = self.conv4(self.pool(conv3))\n",
        "        conv5 = self.conv5(self.pool(conv4))\n",
        "\n",
        "        center = self.center(self.pool(conv5))\n",
        "\n",
        "        dec5 = self.dec5(torch.cat([center, conv5], 1))\n",
        "\n",
        "        dec4 = self.dec4(torch.cat([dec5, conv4], 1))\n",
        "        dec3 = self.dec3(torch.cat([dec4, conv3], 1))\n",
        "        dec2 = self.dec2(torch.cat([dec3, conv2], 1))\n",
        "        dec1 = self.dec1(torch.cat([dec2, conv1], 1))\n",
        "\n",
        "        if self.num_classes > 1:\n",
        "            x_out = F.log_softmax(self.final(dec1), dim=1)\n",
        "        else:\n",
        "            x_out = self.final(dec1)\n",
        "\n",
        "        return x_out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wljnsUB07zgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import glob\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "from torch.utils import data\n",
        "\n",
        "from pathlib import Path\n",
        "from torch.nn import functional as F\n",
        "from torch.autograd import Variable\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "# import models\n",
        "# from utils import *\n",
        "# from loss import *\n",
        "%matplotlib inline\n",
        "\n",
        "from albumentations import (ToFloat, \n",
        "    CLAHE, RandomRotate90, Transpose, ShiftScaleRotate, Blur, OpticalDistortion, \n",
        "    GridDistortion, HueSaturationValue, IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, \n",
        "    MedianBlur, IAAPiecewiseAffine, IAASharpen, IAAEmboss, RandomContrast, RandomBrightness, \n",
        "    Flip, OneOf, Compose, PadIfNeeded, RandomCrop, Normalize, HorizontalFlip, Resize, VerticalFlip,\n",
        "    RandomCrop\n",
        "    \n",
        ")\n",
        "import albumentations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04ljgVuo7zg9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "height_req, width_req = 640, 640\n",
        "req_size = (height_req, width_req)\n",
        "height_orig, width_orig = 565, 584"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LA3a9tkt9uN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logoOverlay(image,logo,alpha=1.0,x=0, y=0, scale=1.0):\n",
        "    (h, w) = image.shape[:2]\n",
        "    image = np.dstack([image, np.ones((h, w), dtype=\"uint8\") * 255])\n",
        "    overlay = cv2.resize(logo, None,fx=scale,fy=scale)\n",
        "    (wH, wW) = overlay.shape[:2]\n",
        "    output = image.copy()\n",
        "    # blend the two images together using transparent overlays\n",
        "    try:\n",
        "        if x<0 : x = w+x\n",
        "        if y<0 : y = h+y\n",
        "        if x+wW > w: wW = w-x  \n",
        "        if y+wH > h: wH = h-y\n",
        "        opacity= random.randint(1, 4) / 10\n",
        "        overlay=cv2.addWeighted(output[y:y+wH, x:x+wW],alpha,overlay[:wH,:wW],opacity,0)\n",
        "        output[y:y+wH, x:x+wW ] = overlay\n",
        "    except Exception as e:\n",
        "        print(\"Error: Logo position is overshooting image!\")\n",
        "        print(e)\n",
        "    output= output[:,:,:3]\n",
        "    return output\n",
        "\n",
        "def overlay_blobs(background):\n",
        "  # background = cv2.imread(im_path)\n",
        "  xmax, ymax = background.shape[:2]\n",
        "  n_blobs = random.randint(1, 3)\n",
        "  for b in range(n_blobs):\n",
        "    blob_id = random.randint(0, 399)\n",
        "    blob_path = f\"img/{blob_id}.png\"\n",
        "    overlay = cv2.imread(blob_path, cv2.IMREAD_UNCHANGED)\n",
        "    try:\n",
        "      overlay[np.where((overlay==[255, 255, 255, 0]).all(axis=2))] = np.array([0, 0, 0, 0])\n",
        "    except:\n",
        "      print(overlay.shape)\n",
        "      return background\n",
        "    gray_num = random.randint(10, 250)\n",
        "    scale = random.randint(1, 10) / 10\n",
        "    x = random.randint(int(xmax*0.1), int(xmax*0.9))\n",
        "    y = random.randint(int(ymax*0.1), int(ymax*0.9))\n",
        "    overlay[np.where((overlay!=[0,0, 0, 0]).any(axis=2))] = np.array([gray_num, gray_num, gray_num, 1])\n",
        "    background = logoOverlay(background,overlay,scale=scale,y=y,x=x)\n",
        "  return background"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgA_8VmT7zhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "class DriveDataset(data.Dataset):\n",
        "    def __init__(self, root_path, file_list, aug = False, mode='train'):\n",
        "        \"\"\" Intialize the dataset\n",
        "        \"\"\"\n",
        "        self.file_list = file_list\n",
        "        self.root_path = root_path\n",
        "        self.image_folder = os.path.join(self.root_path, \"images/\")\n",
        "        self.mask_folder = os.path.join(self.root_path, \"masks/\")\n",
        "        self.mode = mode\n",
        "        self.aug = aug\n",
        "        self.pad = PadIfNeeded(p=1, \n",
        "                               min_height=height_req, \n",
        "                               min_width=width_req, \n",
        "                               border_mode=cv2.BORDER_CONSTANT)\n",
        "        if self.aug:\n",
        "            self.transform = Compose([ Resize(*req_size),\n",
        "                                RandomRotate90(),\n",
        "                                Transpose(),\n",
        "                                Flip(),\n",
        "                                Blur(),\n",
        "                                RandomBrightness(),\n",
        "                                ShiftScaleRotate(),\n",
        "                                OneOf([Compose([RandomCrop(height_req//2, width_req//2), Resize(*req_size)]),\n",
        "                                       Compose([RandomCrop(height_req//4, width_req//4), Resize(*req_size)]),\n",
        "                                       GaussNoise()\n",
        "                                       ])                             \n",
        "\n",
        "                            ])\n",
        "        else:\n",
        "            self.transform = transforms.Compose([transforms.ToPILImage(),\n",
        "                                                transforms.Resize(req_size),\n",
        "                                                transforms.ToTensor()])\n",
        "                                                \n",
        "            \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\" Get a sample from the dataset\n",
        "        \"\"\"\n",
        "        image_path = os.path.join(self.image_folder, self.file_list[index] + \".png\")\n",
        "        mask_path  = os.path.join(self.mask_folder,  self.file_list[index] + \".png\")\n",
        "        image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
        "        pad = self.pad(image=image)\n",
        "        image = pad['image']\n",
        "        \n",
        "\n",
        "        if self.mode == 'train':\n",
        "            mask = cv2.imread(mask_path, 0)\n",
        "            pad = self.pad(image=mask)\n",
        "            mask = pad['image']\n",
        "            blob_proba = random.randint(1, 100) / 100\n",
        "            if blob_proba < 0.4:\n",
        "                image = overlay_blobs(image)\n",
        "            \n",
        "        if self.aug:\n",
        "            if self.mode == 'train':\n",
        "                data = {\"image\": image, \"mask\": mask}\n",
        "            else:\n",
        "                data = {\"image\": image}\n",
        "                \n",
        "            transformed = self.transform(**data)\n",
        "            \n",
        "            image = transformed['image'].astype('float32') / 255.\n",
        "            image = np.transpose(image, (2, 0, 1))\n",
        "            \n",
        "            if self.mode == 'train':\n",
        "                return image, transformed['mask'][np.newaxis, :, :].astype('float32') / 255.\n",
        "            else:\n",
        "                return image\n",
        "        else:\n",
        "            if self.mode == 'train':\n",
        "                return self.transform(image), mask[np.newaxis, :, :].astype('float32') / 255.\n",
        "            return self.transform(image)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.file_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUCrdpcF7zhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = \"train/\"\n",
        "file_list = [f.split('/')[-1].split('.')[0] for f in sorted(glob.glob(train_path + \"images/\" + '*png'))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS9JZ1KZ7zhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_list_val = file_list[::10]\n",
        "file_list_train = [f for f in file_list if f not in file_list_val]\n",
        "\n",
        "dataset_train = DriveDataset(train_path, file_list_train, aug=True)\n",
        "dataset_val = DriveDataset(train_path, file_list_val, aug=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcpsKPjB7zhF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image, mask = next(iter(data.DataLoader(dataset_train, batch_size=4, shuffle=True)))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2awYFWW7zhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeFbaQab7zhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask.data.numpy().squeeze().shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "QQKsl1oH7zhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images, masks = next(iter(data.DataLoader(dataset_train, batch_size = 4)))\n",
        "\n",
        "plt.figure(figsize=(16,16))\n",
        "plt.subplot(211)\n",
        "plt.imshow(torchvision.utils.make_grid(images).data.numpy().transpose((1,2,0)))\n",
        "plt.subplot(212)\n",
        "plt.imshow(torchvision.utils.make_grid(masks).data.numpy().transpose((1,2,0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81FA-kV0hmWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, epoch, lr, loss_fn, save2path):\n",
        "  model = model.cuda()\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  loader_train = data.DataLoader(dataset_train, \n",
        "                                batch_size=4, \n",
        "                                shuffle=True)\n",
        "\n",
        "  loader_val   = data.DataLoader(dataset_val, \n",
        "                                batch_size=4, \n",
        "                                shuffle=False)\n",
        "\n",
        "  for e in range(epoch):    \n",
        "      train_loss = []\n",
        "      train_dice = []\n",
        "      train_jaccard = []\n",
        "\n",
        "      for image, mask in loader_train:\n",
        "          image, mask = image.cuda(), mask.cuda()\n",
        "          \n",
        "          optimizer.zero_grad()\n",
        "          y_pred = model(image)\n",
        "\n",
        "          loss = loss_fn(y_pred, mask)\n",
        "          dice = dice_clamp(torch.sigmoid(y_pred).contiguous(), mask.contiguous())\n",
        "          jaccard = jaccard_clamp(torch.sigmoid(y_pred).contiguous(), mask.contiguous())\n",
        "          loss.backward()\n",
        "\n",
        "          optimizer.step()\n",
        "          \n",
        "          train_loss.append(loss.item())\n",
        "          train_dice.append(dice.item())\n",
        "          train_jaccard.append(jaccard.item())\n",
        "\n",
        "          \n",
        "      val_loss = []\n",
        "      val_dice = []\n",
        "      val_jaccard = []\n",
        "      for image, mask in loader_val:\n",
        "          image, mask = image.cuda(), mask.cuda()\n",
        "          y_pred = model(image)\n",
        "\n",
        "          loss = loss_fn(y_pred, mask)\n",
        "          dice = dice_clamp(torch.sigmoid(y_pred).contiguous(), mask.contiguous())\n",
        "          jaccard = jaccard_clamp(torch.sigmoid(y_pred).contiguous(), mask.contiguous())\n",
        "          \n",
        "          val_loss.append(loss.item())\n",
        "          val_dice.append(dice.item())\n",
        "          val_jaccard.append(jaccard.item())\n",
        "          \n",
        "      print(\"epoch: %d, train_loss: %.3f, train_dice: %.3f, train_jaccard: %.3f, val_loss: %.3f, val_dice: %.3f, val_jaccard: %.3f\" % \n",
        "            (e, np.mean(train_loss),np.mean(train_dice),np.mean(train_jaccard), \n",
        "                np.mean(val_loss),np.mean(val_dice),np.mean(val_jaccard)))\n",
        "  save_checkpoint(save2path, model, optimizer)\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DmSr0Cb0KXV",
        "colab_type": "text"
      },
      "source": [
        "# Experiment 1 - Baseline\n",
        "- Resnet43Unet\n",
        "- 25 epochs\n",
        "- CrossEntropyLoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNOlXqBjjSnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(model=ResNet43Unet(), epoch=25, lr=3e-4, loss_fn=torch.nn.CrossEntropyLoss(), save2path=\"baseline.pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7XGAb4Y0ZZ4",
        "colab_type": "text"
      },
      "source": [
        "# Experiment 2 - Unet11\n",
        "- Unet11\n",
        "- 25 epochs\n",
        "- CrossEntropyLoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UkZBTGXSklGQ",
        "colab": {}
      },
      "source": [
        "train(model=UNet11(), epoch=25, lr=3e-4, loss_fn=torch.nn.CrossEntropyLoss(), save2path=\"unet11_25e_BCE.pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iCD6PvALlCBj"
      },
      "source": [
        "# Experiment 3 - DiceLoss \n",
        "- ResNet43\n",
        "- 25 epochs\n",
        "- DiceLoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn_5bAqx3pm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(model=ResNet43Unet(), epoch=40, lr=3e-4, loss_fn=DiceLoss(), save2path=\"resunet_40e_dice.pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn9sgxNPA9-y",
        "colab_type": "text"
      },
      "source": [
        "# Experiment 4 - BCEDiceLoss \n",
        "- UNet11\n",
        "- 25 epochs\n",
        "- BCEDiceLoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ASlDuGdJA3--",
        "colab": {}
      },
      "source": [
        "train(model=UNet11(), epoch=25, lr=3e-4, loss_fn=BCEDiceLoss(), save2path=\"unet_25e_bcedice.pth\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GihqLdyTIVp5"
      },
      "source": [
        "# * Experiment 5 - BCEDiceLoss \n",
        "- ResNet\n",
        "- 25 epochs\n",
        "- BCEDiceLoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tQDsiKETIVqF",
        "colab": {}
      },
      "source": [
        "train(model=ResNet43Unet(), epoch=25, lr=3e-4, loss_fn=BCEDiceLoss(), save2path=\"resunet_25e_bcedice.pth\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oBGlTafzI2Tu"
      },
      "source": [
        "# Experiment 6 - BCEDiceLoss \n",
        "- UNet11\n",
        "- 100 epochs\n",
        "- BCEDiceLoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G7RlAQu_I2T2",
        "colab": {}
      },
      "source": [
        "train(model=UNet11(), epoch=100, lr=3e-4, loss_fn=BCEDiceLoss(), save2path=\"unet_100e_bcedice.pth\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uHCv-nfO565e"
      },
      "source": [
        "# Experiment 8\n",
        "- ResNet\n",
        "- 100 epochs\n",
        "- BCEDiceLoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1MwVbIzmWgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(model=ResNet43Unet(), epoch=100, lr=3e-4, loss_fn=BCEDiceLoss(), save2path=\"resunet_100e_bcedice.pth\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5y_hcUQx899y",
        "colab_type": "text"
      },
      "source": [
        "# Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaQUjJMQ9Aad",
        "colab_type": "text"
      },
      "source": [
        "# Experiment 10\n",
        "Add all augmentation from cells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDic2xXQL8Ux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "class DriveDataset(data.Dataset):\n",
        "    def __init__(self, root_path, file_list, aug = False, mode='train'):\n",
        "        \"\"\" Intialize the dataset\n",
        "        \"\"\"\n",
        "        self.file_list = file_list\n",
        "        self.root_path = root_path\n",
        "        self.image_folder = os.path.join(self.root_path, \"images/\")\n",
        "        self.mask_folder = os.path.join(self.root_path, \"masks/\")\n",
        "        self.mode = mode\n",
        "        self.aug = aug\n",
        "        self.pad = PadIfNeeded(p=1, \n",
        "                               min_height=height_req, \n",
        "                               min_width=width_req, \n",
        "                               border_mode=cv2.BORDER_CONSTANT)\n",
        "        if self.aug:\n",
        "            self.transform = Compose([ Resize(*req_size),\n",
        "                                RandomRotate90(p=0.5),\n",
        "                                Transpose(p=0.3),\n",
        "                                Flip(p=0.5),\n",
        "                                Blur(p=0.3),\n",
        "                                RandomBrightness(p=0.3),\n",
        "                                ShiftScaleRotate(p=0.3),\n",
        "                                OneOf([Compose([RandomCrop(height_req//2, width_req//2), Resize(*req_size)]),\n",
        "                                       Compose([RandomCrop(height_req//4, width_req//4), Resize(*req_size)]),\n",
        "                                       GaussNoise()\n",
        "                                       ])                             \n",
        "\n",
        "                            ])\n",
        "        else:\n",
        "            self.transform = transforms.Compose([transforms.ToPILImage(),\n",
        "                                                transforms.Resize(req_size),\n",
        "                                                transforms.ToTensor()])\n",
        "                                                \n",
        "            \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\" Get a sample from the dataset\n",
        "        \"\"\"\n",
        "        image_path = os.path.join(self.image_folder, self.file_list[index] + \".png\")\n",
        "        mask_path  = os.path.join(self.mask_folder,  self.file_list[index] + \".png\")\n",
        "        image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
        "        pad = self.pad(image=image)\n",
        "        image = pad['image']\n",
        "        \n",
        "\n",
        "        if self.mode == 'train':\n",
        "            mask = cv2.imread(mask_path, 0)\n",
        "            pad = self.pad(image=mask)\n",
        "            mask = pad['image']\n",
        "            blob_proba = random.randint(1, 100) / 100\n",
        "            if blob_proba < 0.4:\n",
        "                image = overlay_blobs(image)\n",
        "            \n",
        "        if self.aug:\n",
        "            if self.mode == 'train':\n",
        "                data = {\"image\": image, \"mask\": mask}\n",
        "            else:\n",
        "                data = {\"image\": image}\n",
        "                \n",
        "            transformed = self.transform(**data)\n",
        "            \n",
        "            image = transformed['image'].astype('float32') / 255.\n",
        "            image = np.transpose(image, (2, 0, 1))\n",
        "            \n",
        "            if self.mode == 'train':\n",
        "                return image, transformed['mask'][np.newaxis, :, :].astype('float32') / 255.\n",
        "            else:\n",
        "                return image\n",
        "        else:\n",
        "            if self.mode == 'train':\n",
        "                return self.transform(image), mask[np.newaxis, :, :].astype('float32') / 255.\n",
        "            return self.transform(image)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.file_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9Go67oWmp2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(model=ResNet43Unet(), epoch=40, lr=3e-4, loss_fn=BCEDiceLoss(), save2path=\"resunet_40e_bcedice.pth\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIaZ2-6X9Evq",
        "colab_type": "text"
      },
      "source": [
        "# Experiment 11 \n",
        "Add blob-like figures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc4XvWDE1JWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate blobs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LXKJPHa9Iy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from scipy.special import binom\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "bernstein = lambda n, k, t: binom(n,k)* t**k * (1.-t)**(n-k)\n",
        "\n",
        "def bezier(points, num=200):\n",
        "    N = len(points)\n",
        "    t = np.linspace(0, 1, num=num)\n",
        "    curve = np.zeros((num, 2))\n",
        "    for i in range(N):\n",
        "        curve += np.outer(bernstein(N - 1, i, t), points[i])\n",
        "    return curve\n",
        "\n",
        "class Segment():\n",
        "    def __init__(self, p1, p2, angle1, angle2, **kw):\n",
        "        self.p1 = p1; self.p2 = p2\n",
        "        self.angle1 = angle1; self.angle2 = angle2\n",
        "        self.numpoints = kw.get(\"numpoints\", 100)\n",
        "        r = kw.get(\"r\", 0.3)\n",
        "        d = np.sqrt(np.sum((self.p2-self.p1)**2))\n",
        "        self.r = r*d\n",
        "        self.p = np.zeros((4,2))\n",
        "        self.p[0,:] = self.p1[:]\n",
        "        self.p[3,:] = self.p2[:]\n",
        "        self.calc_intermediate_points(self.r)\n",
        "\n",
        "    def calc_intermediate_points(self,r):\n",
        "        self.p[1,:] = self.p1 + np.array([self.r*np.cos(self.angle1),\n",
        "                                    self.r*np.sin(self.angle1)])\n",
        "        self.p[2,:] = self.p2 + np.array([self.r*np.cos(self.angle2+np.pi),\n",
        "                                    self.r*np.sin(self.angle2+np.pi)])\n",
        "        self.curve = bezier(self.p,self.numpoints)\n",
        "\n",
        "\n",
        "def get_curve(points, **kw):\n",
        "    segments = []\n",
        "    for i in range(len(points)-1):\n",
        "        seg = Segment(points[i,:2], points[i+1,:2], points[i,2],points[i+1,2],**kw)\n",
        "        segments.append(seg)\n",
        "    curve = np.concatenate([s.curve for s in segments])\n",
        "    return segments, curve\n",
        "\n",
        "def ccw_sort(p):\n",
        "    d = p-np.mean(p,axis=0)\n",
        "    s = np.arctan2(d[:,0], d[:,1])\n",
        "    return p[np.argsort(s),:]\n",
        "\n",
        "def get_bezier_curve(a, rad=0.2, edgy=0):\n",
        "    \"\"\" given an array of points *a*, create a curve through\n",
        "    those points. \n",
        "    *rad* is a number between 0 and 1 to steer the distance of\n",
        "          control points.\n",
        "    *edgy* is a parameter which controls how \"edgy\" the curve is,\n",
        "           edgy=0 is smoothest.\"\"\"\n",
        "    p = np.arctan(edgy)/np.pi+.5\n",
        "    a = ccw_sort(a)\n",
        "    a = np.append(a, np.atleast_2d(a[0,:]), axis=0)\n",
        "    d = np.diff(a, axis=0)\n",
        "    ang = np.arctan2(d[:,1],d[:,0])\n",
        "    f = lambda ang : (ang>=0)*ang + (ang<0)*(ang+2*np.pi)\n",
        "    ang = f(ang)\n",
        "    ang1 = ang\n",
        "    ang2 = np.roll(ang,1)\n",
        "    ang = p*ang1 + (1-p)*ang2 + (np.abs(ang2-ang1) > np.pi )*np.pi\n",
        "    ang = np.append(ang, [ang[0]])\n",
        "    a = np.append(a, np.atleast_2d(ang).T, axis=1)\n",
        "    s, c = get_curve(a, r=rad, method=\"var\")\n",
        "    x,y = c.T\n",
        "    return x,y, a\n",
        "\n",
        "\n",
        "def get_random_points(n=5, scale=0.8, mindst=None, rec=0):\n",
        "    \"\"\" create n random points in the unit square, which are *mindst*\n",
        "    apart, then scale them.\"\"\"\n",
        "    mindst = mindst or .7/n\n",
        "    a = np.random.rand(n,2)\n",
        "    d = np.sqrt(np.sum(np.diff(ccw_sort(a), axis=0), axis=1)**2)\n",
        "    if np.all(d >= mindst) or rec>=200:\n",
        "        return a*scale\n",
        "    else:\n",
        "        return get_random_points(n=n, scale=scale, mindst=mindst, rec=rec+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwtxDc9EDGer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(model=ResNet43Unet(), epoch=80, lr=2e-5, loss_fn=BCEDiceLoss(), save2path=\"resunet_80e_bcedice_blob.pth\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AQ9UIcIBDMGx",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgiJWVzLm8aF",
        "colab_type": "text"
      },
      "source": [
        "# Test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gaNEteDfDMG_",
        "colab": {}
      },
      "source": [
        "test_path = \"test/\"\n",
        "test_file_list = glob.glob(os.path.join(test_path, 'images', '*.png'))\n",
        "test_file_list = [\".\".join(f.split('/')[-1].split('.')[:-1]) for f in test_file_list]\n",
        "print('First 3 names of test files:', test_file_list[:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KP9qJ7fbDMHD",
        "colab": {}
      },
      "source": [
        "print(f\"Test size: {len(test_file_list)}\")\n",
        "test_dataset = DriveDataset(train_path, file_list, mode=None)\n",
        "all_images = []\n",
        "all_predictions = []\n",
        "for image in tqdm_notebook(data.DataLoader(test_dataset, batch_size = 2)):\n",
        "    image = image.cuda()\n",
        "    print(image.shape)\n",
        "    all_images.append(image.cpu().data.numpy())\n",
        "    y_pred = torch.sigmoid(model(image)).cpu().data.numpy()\n",
        "    all_predictions.append(y_pred)\n",
        "all_predictions_stacked = np.vstack(all_predictions)[:, 0, :, :]\n",
        "all_images = np.vstack(all_images)[:, :, :, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "594EjeoqDMHI",
        "colab": {}
      },
      "source": [
        "i = 14\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(all_images[i].transpose(1,2,0))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(all_predictions_stacked[i])\n",
        "print(mask.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hQv9qYEVDMHN",
        "colab": {}
      },
      "source": [
        "i = 8\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(all_images[i].transpose(1,2,0))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(all_predictions_stacked[i])\n",
        "print(mask.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}